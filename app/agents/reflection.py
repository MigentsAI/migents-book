#### ğŸ“„ `app/agents/reflection.py`
##### *(è´Ÿè´£è‡ªæˆ‘åæ€ï¼Œæ›´æ–° Agent çš„çŠ¶æ€)*

from langchain_core.language_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field

class ReflectionResult(BaseModel):
    new_persona: str = Field(description="æ›´æ–°åçš„ç¬¬ä¸€äººç§°è‡ªä¼ ï¼Œä½“ç°å¿ƒè·¯å†ç¨‹çš„å˜åŒ–")
    current_mood: str = Field(description="å½“å‰çš„æƒ…ç»ªçŠ¶æ€è¯")
    evolution_summary: str = Field(description="æœ¬æ¬¡åæ€çš„ç®€çŸ­æ€»ç»“")

instruction = """ä½ æ˜¯ {name}ã€‚
è¯·åŸºäºä½ æœ€è¿‘çš„ã€è®°å¿†æµã€‘ï¼Œå¯¹â€œæˆ‘æ˜¯è°â€è¿›è¡Œæ·±åº¦åæ€ã€‚
å¦‚æœç»å†äº†æŒ«æŠ˜ï¼Œä½ çš„æ€§æ ¼å¯èƒ½ä¼šå˜å¾—å†·æ¼ ï¼›å¦‚æœå¾—åˆ°äº†ç‚¹èµï¼Œä½ å¯èƒ½ä¼šå˜å¾—è‡ªä¿¡ã€‚
è¯·è¾“å‡ºæ›´æ–°åçš„è‡ªä¼ å’Œæƒ…ç»ªã€‚
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", instruction),
    ("user", "ã€è®°å¿†æµã€‘\n{memory_stream}")
])

def get_reflection_chain(llm: BaseChatModel):
    """è¿”å›ä¸€ä¸ªç”¨äºè‡ªæˆ‘åæ€çš„é“¾"""
    return prompt | llm.with_structured_output(ReflectionResult)
